{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]]\n",
      "[1 0 1 0 1 0 1]\n",
      "[ 9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = range(16) \n",
    "y_ = np.reshape(y,[1,8,2])\n",
    "#a = np.amax(y_,axis=2)\n",
    "#mask = (a > 0)\n",
    "#print(mask)\n",
    "#print(a[mask])\n",
    "#print(a[0][1:])\n",
    "\n",
    "print(y_)\n",
    "idxes = np.where(y_ > 8)\n",
    "print(idxes[-1])\n",
    "print(y_[idxes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-1eb794808f6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbbox_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mbbox_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "bbox_img = tf.constant([[0., 0., 1., 1.]])\n",
    "\n",
    "if bbox_img.get_shape().is_fully_defined():\n",
    "    t = bbox_img.get_shape().as_list()\n",
    "    bbox_img = tf.reshape(bbox_img,[2,2])\n",
    "    print(t)    \n",
    "else:\n",
    "    print(1)\n",
    "with tf.Session():\n",
    "    print(bbox_img.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros([1,18,18,4,21])\n",
    "\n",
    "c = a.shape\n",
    "d = c[0]\n",
    "e = c[-1]\n",
    "print(len(c))\n",
    "\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8, 2)\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "y = range(16) \n",
    "y_ = np.reshape(y,[1,8,2])\n",
    "a.append(y_)\n",
    "y2 = np.reshape(y,[1,8,2])\n",
    "a.append(y2)\n",
    "a = np.concatenate(a, 0)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-3bc74d884452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbbox_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbbox_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "bbox_img = tf.constant([[0., 0., 1., 1.]])\n",
    "\n",
    "t = bbox_img.get_shape()\n",
    "bbox_img = tf.reshape(bbox_img,[2,2])\n",
    "print(t)    \n",
    "\n",
    "with tf.Session():\n",
    "    print(bbox_img.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape (18, 18, 4, 21) must have rank 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    599\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" % (self,\n\u001b[1;32m--> 600\u001b[1;33m                                                                        other))\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (18, 18, 4, 21) and (?, ?, ?, ?, ?) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    560\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (18, 18, 4, 21) and (?, ?, ?, ?, ?) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-8dd1c991f4a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[1;34m(self, rank)\u001b[0m\n\u001b[0;32m    630\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwith_rank_at_least\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape (18, 18, 4, 21) must have rank 5"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(18*18*4*21)\n",
    "x = tf.convert_to_tensor(a)\n",
    "y = tf.reshape(x,[1,18,18,4,21])\n",
    "\n",
    "if y.get_shape().is_fully_defined():\n",
    "    print(111)\n",
    "    \n",
    "shape = y.get_shape().with_rank(5).as_list()\n",
    "print(shape)\n",
    "\n",
    "dynamic_shape = tf.unstack(tf.shape(y), 5)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(dynamic_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0.10717734\n",
      "1\n",
      "0.11486983\n",
      "2\n",
      "0.123114444\n",
      "3\n",
      "0.1319508\n",
      "4\n",
      "0.14142136\n",
      "5\n",
      "0.15157166\n",
      "6\n",
      "0.16245048\n",
      "7\n",
      "0.17411011\n",
      "8\n",
      "0.1866066\n",
      "9\n",
      "0.2\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf;  \n",
    "import numpy as np;  \n",
    "import matplotlib.pyplot as plt;  \n",
    " \n",
    "x = tf.placeholder(tf.float32, shape=[None, 1], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1], name='y')\n",
    "w = tf.Variable(tf.constant(0.0))\n",
    " \n",
    "global_steps = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(0.1, global_steps, 10, 2, staircase=False)\n",
    "loss = tf.pow(w*x-y, 2)\n",
    " \n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_steps)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in range(10):\n",
    "        sess.run(train_step, feed_dict={x:np.linspace(1,2,10).reshape([10,1]),y:np.linspace(1,2,10).reshape([10,1])})\n",
    "        print(sess.run(learning_rate))\n",
    "        print(sess.run(global_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "a=[1]+[len([18,18,4,4])]*3\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 6, 6]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 6, 6]\n",
      "19\n",
      "Tensor(\"batch:0\", shape=(32, 300, 300, 3), dtype=float32)\n",
      "Tensor(\"batch:1\", shape=(32, 38, 38, 4), dtype=int64)\n",
      "Tensor(\"batch:2\", shape=(32, 19, 19, 6), dtype=int64)\n",
      "Tensor(\"batch:3\", shape=(32, 10, 10, 6), dtype=int64)\n",
      "Tensor(\"batch:4\", shape=(32, 5, 5, 6), dtype=int64)\n",
      "Tensor(\"batch:5\", shape=(32, 3, 3, 4), dtype=int64)\n",
      "Tensor(\"batch:6\", shape=(32, 1, 1, 4), dtype=int64)\n",
      "Tensor(\"batch:7\", shape=(32, 38, 38, 4, 4), dtype=float32)\n",
      "Tensor(\"batch:8\", shape=(32, 19, 19, 6, 4), dtype=float32)\n",
      "Tensor(\"batch:9\", shape=(32, 10, 10, 6, 4), dtype=float32)\n",
      "Tensor(\"batch:10\", shape=(32, 5, 5, 6, 4), dtype=float32)\n",
      "Tensor(\"batch:11\", shape=(32, 3, 3, 4, 4), dtype=float32)\n",
      "Tensor(\"batch:12\", shape=(32, 1, 1, 4, 4), dtype=float32)\n",
      "Tensor(\"batch:13\", shape=(32, 38, 38, 4), dtype=float32)\n",
      "Tensor(\"batch:14\", shape=(32, 19, 19, 6), dtype=float32)\n",
      "Tensor(\"batch:15\", shape=(32, 10, 10, 6), dtype=float32)\n",
      "Tensor(\"batch:16\", shape=(32, 5, 5, 6), dtype=float32)\n",
      "Tensor(\"batch:17\", shape=(32, 3, 3, 4), dtype=float32)\n",
      "Tensor(\"batch:18\", shape=(32, 1, 1, 4), dtype=float32)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import preprocessing_factory\n",
    "import tf_utils\n",
    "from nets import nets_factory\n",
    "import tensorflow as tf\n",
    "from datasets import dataset_factory\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "DATASET_DIR = 'tfrecords'\n",
    "\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'batch_size', 32, 'The number of samples in each batch.')\n",
    "tf.app.flags.DEFINE_integer(\n",
    "    'num_readers', 4,\n",
    "    'The number of parallel readers that read data from the dataset.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_name', 'pascalvoc_2007', 'The name of the dataset to load.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_split_name', 'train', 'The name of the train/test split.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_dir', DATASET_DIR, 'The directory where the dataset files are stored.')\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "def main(_):\n",
    "    ssd_class = nets_factory.get_network(\"ssd_300_vgg\")\n",
    "    #对SSDNet的参数进行修改（num_classes）\n",
    "    ssd_params = ssd_class.default_params._replace(num_classes=21)\n",
    "    #ssd_net = 新的ssd_vgg_300.SSDNet\n",
    "    ssd_net = ssd_class(ssd_params)\n",
    "    #ssd_shape = SSDNet默认输入的图像大小\n",
    "    ssd_shape = ssd_net.params.img_shape\n",
    "    #生成图像所有的anchors，保存其坐标：[Y,X,H,W]\n",
    "    ssd_anchors = ssd_net.anchors(ssd_shape)\n",
    "    batch_shape = [1] + [len(ssd_anchors)] * 3\n",
    "    print(batch_shape)\n",
    "\n",
    "    dataset = dataset_factory.get_dataset(FLAGS.dataset_name, FLAGS.dataset_split_name, FLAGS.dataset_dir)\n",
    "    provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "                    dataset,\n",
    "                    num_readers=FLAGS.num_readers,\n",
    "                    common_queue_capacity=20 * FLAGS.batch_size,\n",
    "                    common_queue_min=10 * FLAGS.batch_size,\n",
    "                    shuffle=True)\n",
    "    [image, shape, glabels, gbboxes] = provider.get(['image', 'shape','object/label','object/bbox'])\n",
    "    image_preprocessing_fn = preprocessing_factory.get_preprocessing(\n",
    "                \"ssd_300_vgg\", is_training=True)\n",
    "    image, glabels, gbboxes = \\\n",
    "        image_preprocessing_fn(image, glabels, gbboxes,\n",
    "                               out_shape=[300,300],\n",
    "                               data_format='NHWC')\n",
    "    gclasses, glocalisations, gscores = \\\n",
    "                    ssd_net.bboxes_encode(glabels, gbboxes, ssd_anchors)\n",
    "\n",
    "    r = tf.train.batch(\n",
    "        tf_utils.reshape_list([image, gclasses, glocalisations, gscores]),\n",
    "        batch_size=32,\n",
    "        num_threads=4,\n",
    "        capacity=5 * 32)\n",
    "    print(len(r))\n",
    "    for i in range(len(r)):\n",
    "        print(r[i])\n",
    "\n",
    "#b_image, b_gclasses, b_glocalisations, b_gscores = r.dequeue()\n",
    "#print(b_gscores)\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 18, 4, 4], [1, 1, 1, 4]]\n",
      "[[1 1 0 0]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = [[18,18,4,4]]\n",
    "a.append([1,1,1,4])\n",
    "print(a)\n",
    "x = tf.convert_to_tensor(a)\n",
    "b = x > 4\n",
    "fb = tf.cast(b, tf.int32)\n",
    "n = tf.reduce_sum(fb)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(fb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 18, 4, 4], [1, 1, 1, 4]]\n",
      "[[1 1 0 0]\n",
      " [0 0 0 0]]\n",
      "[1 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = [[18,18,4,4]]\n",
    "a.append([1,1,1,4])\n",
    "print(a)\n",
    "x = tf.convert_to_tensor(a)\n",
    "b = x > 4\n",
    "fb = tf.cast(b, tf.int32)\n",
    "c = tf.logical_not(b)\n",
    "d = tf.reshape(fb,[-1])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(fb))\n",
    "    print(sess.run(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory: ./VOC2007\n",
      "Output directory: ./tfrecords/train\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Convert a dataset to TFRecords format, which can be easily integrated into\n",
    "a TensorFlow pipeline.\n",
    "\n",
    "Usage:\n",
    "```shell\n",
    "python tf_convert_data.py \\\n",
    "    --dataset_name=pascalvoc \\\n",
    "    --dataset_dir=/tmp/pascalvoc \\\n",
    "    --output_name=pascalvoc \\\n",
    "    --output_dir=/tmp/\n",
    "```\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import pascalvoc_to_tfrecords\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_name', 'pascalvoc',\n",
    "    'The name of the dataset to convert.')\n",
    "\"\"\"\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_dir', None,\n",
    "    'Directory where the original dataset is stored.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'output_name', 'pascalvoc',\n",
    "    'Basename used for TFRecords output files.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'output_dir', './',\n",
    "    'Output directory where to store TFRecords files.')\n",
    "\"\"\"\n",
    "\n",
    "DATASET_DIR=\"./VOC2007\"\n",
    "OUTPUT_DIR=\"./tfrecords/train\"\n",
    "\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'dataset_dir', DATASET_DIR,\n",
    "    'Directory where the original dataset is stored.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'output_name', 'pascalvoc',\n",
    "    'Basename used for TFRecords output files.')\n",
    "tf.app.flags.DEFINE_string(\n",
    "    'output_dir', OUTPUT_DIR,\n",
    "    'Output directory where to store TFRecords files.')\n",
    "\n",
    "\n",
    "\n",
    "def main(_):\n",
    "    if not FLAGS.dataset_dir:\n",
    "        raise ValueError('You must supply the dataset directory with --dataset_dir')\n",
    "    print('Dataset directory:', FLAGS.dataset_dir)\n",
    "    print('Output directory:', FLAGS.output_dir)\n",
    "\n",
    "    if FLAGS.dataset_name == 'pascalvoc':\n",
    "        pascalvoc_to_tfrecords.run(FLAGS.dataset_dir, FLAGS.output_dir, FLAGS.output_name)\n",
    "    else:\n",
    "        raise ValueError('Dataset [%s] was not recognized.' % FLAGS.dataset_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005.xm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./VOC2007/Annotations\"\n",
    "filenames = sorted(os.listdir(path))\n",
    "filename = filenames[0]\n",
    "img_name = filename[:-4]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
